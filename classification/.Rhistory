install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(mod3$finalModel,main="Mushroom Attributes Classification",sub=NA,
palettes=c("Greys","Oranges"))
y_predicted<-predict(mod3,x_test)
df1<-data.frame(Orig=y_test,Pred=y_predicted)
confusionMatrix(table(df1$Orig,df1$Pred)) #<- 100% accuracy again
p1 = 1 - (1/5)^2 -(4/5)^2
p1
library(C50)
install.packages('C50')
library(C50)
install.packages('gmodels')
library(rpart.plot)
install.packages('rpart')
install.packages("rpart")
library(rpart.plot)
library(rpart)
library(rpart.plot)
data(iris)
data <- iris
sam <- sample(1:150,125)
train_data <- data[sam,]
test_data <- data[-sam,]
dtree <- rpart(Species~.,data=train_data)
plotcp(dtree)
dtree.pruned <- prune(dtree, cp=0.01)
prp(dtree.pruned,type=0)
title('Decision Tree for Iris Data')
dtree.pred <- predict(dtree.pruned,test_data[,1:4],type='class')
(dtree.perf <- table(test_data[,5],dtree.pred))
data(iris)
data(iris)
irisRand <- iris[order(runif(150)),]
irisRand <- iris[order(runif(150)),]
iris_train <- irisRand[1:125,]
iris_test <- irisRand[126:150,]
library(ggplot2)
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
library(dplyr)
library(randomForest)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
install.packages("caTools")
library(caTools)
library(party)
install.packages("party")
library(party)
library(party)
data <- read.csv("./xAPI-Edu-Data.csv")
str(data)
summary(data)
ggplot(data = data, aes(x = raisedhands)) + geom_histogram(color = "black") +
scale_x_continuous(breaks = seq(0,100,5)) +
labs(x = "Raised Hands", y = "Student Count")
ggplot(data = data, aes(x = raisedhands)) + geom_histogram(color = "red") +
scale_x_continuous(breaks = seq(0,100,5)) +
labs(x = "Raised Hands", y = "Student Count")
ggplot(data = data, aes(x = raisedhands, color = gender)) + geom_density()
ggplot(data = data, aes(x = raisedhands)) + geom_histogram(color = "red") +
scale_x_continuous(breaks = seq(0,100,5)) +
labs(x = "Raised Hands", y = "Student Count")
ggplot(data = data, aes(x = gender)) + geom_bar() +
labs(x = "Gender", y = "Student Count") +
scale_y_continuous(breaks = seq(0,300,30)) + coord_flip()
ggplot(data = data, aes(x = PlaceofBirth)) + geom_bar(aes(fill = NationalITy)) +
labs(x = "Birth Place", y = "Student Count") + coord_flip()
ggplot(data = data, aes(x = Topic, fill = gender)) + geom_bar() +
labs(x = "Topic", y = "Student Count") +
scale_y_continuous(breaks = seq(0,100,4)) + coord_flip()
ggplot(data = data, aes(x = gender, y = raisedhands)) + geom_boxplot()
ggplot(data = data, aes( x = raisedhands, y = VisITedResources)) + geom_point() +
geom_smooth(method = "lm")
ggplot(data = data, aes(x = raisedhands, color = gender)) + geom_density()
set.seed(55)
split <- sample.split(data$Class, SplitRatio = 0.7)
train <- subset(data, split == T)
cv <- subset(data, split == F)
tree.model <- rpart(Class ~ ., data = train, method = "class", minbucket = 1)
prp(tree.model)
library(C50)
model <- C5.0(default ~ ., data = train)
model <- C5.0(default ~ ., data = train,env=0)
model <- C5.0(data = train)
model <- C5.0(default ~ ., data = train)
model <- C5.0(default ~ ., data = train,type ='class')
cv <- subset(data, split == F)
model <- C5.0(class ~ ., data = train)
data1 <- read.csv("./xAPI-Edu-Data.csv")
str(data1)
summary(data1)
data <- read.csv("./xAPI-Edu-Data.csv")
str(data)
summary(data)
model <- C5.0(data$Class, data = train)
model <- C5.0(train,train$Class)
summary(model)
predictions <- predict(model, cv)
library(gmodels)
CrossTable(preditions, cv$Class,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
prediction <- predict(model, cv)
CrossTable(prediction, cv$Class,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
predictions <- knn(train = train, test =
cv, cl = train$Class, k=3)
ml<-knn(train,cv,cl=train$Class,k=3)
ml<-knn(train,cv,cl=train$Class,k=13)
prp(model)
summary(model)
predictions <- knn(train = train, test =
cv, cl = class, k=21)
predictions <- knn(train = train, test =
cv, cl = class, k=3)
train[,1]
prc_test_pred <- knn(train = train, test = cv,cl = train[,1], k=10)
train_x = data[1:336,]
test_x = daa[337:480,]
test_x = data[337:480,]
train_x<-data[1:336,]
test_x<-data[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
data$Class <- factor(data$Class,levels=c("L","M","H"),
labels=c("low","medial","high"))
table(data$Class)
data$Class <- factor(data$Class,levels=c("L","M","H"),
labels=c("low","medial","high"))
prop.table(table(data$Class))
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
data
data_n <- as.data.frame(lapply(data, normalize))
train_x<-data[1:336,]
test_x<-data[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
train_x
View(test_x)
train_x <- subset(train_x, select = -class )
train_x <- train_x[,17]
test_x <- test_x[,17]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
train_x
View(train_data)
View(test_data)
View(test_data)
View(tree.model)
View(normalize)
data <- read.csv("./xAPI-Edu-Data.csv")
train_x<-data[1:336,]
test_x<-data[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
train_x <- train_x[,17]
View(test_x)
train_x <- train_x[,-17]
train_x <- train_x[,-16]
data <- read.csv("./xAPI-Edu-Data.csv")
table(data$Class)
data$Class <- factor(data$Class,levels=c("L","M","H"),
labels=c("low","medial","high"))
prop.table(table(data$Class))
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
data
data_n <- as.data.frame(lapply(data, normalize))
train_x<-data[1:336,]
test_x<-data[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
train_x <- train_x[,-16]
test_x <- test_x[,-17]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
train_x
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
data <- read.csv("./xAPI-Edu-Data.csv")
table(data$Class)
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
data$Class <- factor(data$Class,levels=c("L","M","H"),
labels=c("low","medial","high"))
prop.table(table(data$Class))
train_x<-data[1:336,]
test_x<-data[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=21)
View(data)
table(data$gender)
a <- sub("M","0",data$gender)
b <- sub("F","1",a)
data$gender <- b
View(data1)
data <- subset(data, select = -gender )
data <- subset(data, select = -NationalITy )
data <- subset(data, select = -PlaceofBirth )
data <- subset(data, select = -StageID )
data <- subset(data, select = -GradeID )
data <- subset(data, select = -SectionID )
data <- subset(data, select = -Topic )
data <- subset(data, select = -Semester )
data <- subset(data, select = -Relation )
data <- subset(data, select = -ParentAnsweringSurvey )
data <- subset(data, select = -ParentschoolSatisfaction
)
data <- subset(data, select = -StudentAbsenceDays )
prop.table(table(data$Class))
train_x<-data[1:336,]
test_x<-data[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=21)
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=21)
View(train_x)
train_x
train_label
train_x
data <- data[1:4]
data
train_x<-data[1:336,]
test_x<-data[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=21)
test_label
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
train_label
data_y <- data[5]
data_y <- data[5:]
data_x <- data[1:4]
data_y <- data[5]
data_x <- data[1:4]
train_x<-data_x[1:336,]
test_x<-data_x[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=21)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
data <- read.csv("./xAPI-Edu-Data.csv")
table(data$Class)
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
data$Class <- factor(data$Class,levels=c("L","M","H"),
labels=c("low","medial","high"))
data <- subset(data, select = -gender )
data <- subset(data, select = -NationalITy )
data <- subset(data, select = -PlaceofBirth )
data <- subset(data, select = -StageID )
data <- subset(data, select = -GradeID )
data <- subset(data, select = -SectionID )
data <- subset(data, select = -Topic )
data <- subset(data, select = -Semester )
data <- subset(data, select = -Relation )
data <- subset(data, select = -ParentAnsweringSurvey )
data <- subset(data, select = -ParentschoolSatisfaction
)
data <- subset(data, select = -StudentAbsenceDays )
data_x <- data[1:4]
train_x<-data_x[1:336,]
test_x<-data_x[337:480,]
train_label<-data[1:336,1]
test_label <- data[337:480,1]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=21)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
train_label<-data[1:336,5]
test_label <- data[337:480,5]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=21)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=3)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=10)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=30)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
install.packages("psych")
a1 <- c(“f”,”f”,”b”,”b”,”c,”c”)
a1 <- c(“f”,”f”,”b”,”b”,”c”)
a1 <- c("a","b","c","d")
class.ind(a1)
wineRed = read.csv("./winequality-red.csv", header = TRUE, sep=",", na.strings= "*")
set.seed(4242)
wineRed$quality = lapply(wineRed[,12], function (x)
{
if(x >6)  { "A"}
else if(x >4)  {"B"}
else { "C"}
})
View(wineRed)
data_x <- wineRed[1:11]
train_x<-data_x[1:1120,]
test_x<-data_x[1121:1599,]
train_label<-wineRed[1:1120,12]
test_label <- wineRed[1121:1599,12]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=30)
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
data_x <- wineRed[1:11]
train_x<-data_x[1:1120,]
test_x<-data_x[1121:1599,]
train_label<-wineRed[1:1120,12]
test_label <- wineRed[1121:1599,12]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=30)
train_label1<-wineRed[1:1120,12]
test_label2 <- wineRed[1121:1599,12]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label1, k=30)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
train_label1
data <- read.csv("./xAPI-Edu-Data.csv")
table(data$Class)
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
install.packages("psych")
data$Class <- factor(data$Class,levels=c("L","M","H"),
labels=c("low","medial","high"))
data <- subset(data, select = -gender )
data <- subset(data, select = -NationalITy )
data <- subset(data, select = -PlaceofBirth )
data <- subset(data, select = -StageID )
data <- subset(data, select = -GradeID )
data <- subset(data, select = -SectionID )
data <- subset(data, select = -Topic )
data <- subset(data, select = -Semester )
data <- subset(data, select = -Relation )
data <- subset(data, select = -ParentAnsweringSurvey )
data <- subset(data, select = -ParentschoolSatisfaction
)
data <- subset(data, select = -StudentAbsenceDays )
data_x <- data[1:4]
train_x<-data_x[1:336,]
test_x<-data_x[337:480,]
train_label<-data[1:336,5]
test_label <- data[337:480,5]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=30)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
train_label
wineRed = read.csv("./winequality-red.csv", header = TRUE, sep=",", na.strings= "*")
set.seed(4242)
wineRed$quality = lapply(wineRed[,12], function (x)
{
if(x > 5)  { "good"}
else { "bad"}
})
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
data_x <- wineRed[1:11]
train_x<-data_x[1:1120,]
test_x<-data_x[1121:1599,]
train_label1<-wineRed[1:1120,12]
train_label1
train_label1<-wineRed[1:1120,12]
test_label2 <- wineRed[1121:1599,12]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label1, k=30)
wineRed$quality <- factor(wineRed$quality,levels=c("G","B"),
labels=c("good","bad"))
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
data_x <- wineRed[1:11]
train_x<-data_x[1:1120,]
test_x<-data_x[1121:1599,]
train_label1<-wineRed[1:1120,12]
test_label2 <- wineRed[1121:1599,12]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label1, k=30)
wineRed$quality <- factor(wineRed$quality,levels=c("G","B"),
labels=c("good","bad"))
wineRed$quality = lapply(wineRed[,12], function (x)
{
if(x > 5)  { "good"}
else { "bad"}
})
wineRed = read.csv("./winequality-red.csv", header = TRUE, sep=",", na.strings= "*")
set.seed(4242)
wineRed$quality = lapply(wineRed[,12], function (x)
{
if(x > 5)  { "good"}
else { "bad"}
})
wineRed$quality <- factor(wineRed$quality,levels=c("G","B"),
labels=c("good","bad"))
View(data)
wineRed$quality = lapply(wineRed[,12], function (x)
{
if(x > 5)  { "good"}
else { "bad"}
})
wineRed$quality <- factor(wineRed$quality,levels=c("good","bad"),
labels=c("G","B"))
wineRed = read.csv("./winequality-red.csv", header = TRUE, sep=",", na.strings= "*")
set.seed(4242)
wineRed$quality = lapply(wineRed[,12], function (x)
{
if(x > 5)  { "good"}
else { "bad"}
})
wineRed$quality <- factor(wineRed$quality,levels=c("good","bad"),
labels=c("G","B"))
library(dplyr)
library(randomForest)
library(class)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
library(caTools)
library(party)
data_x <- wineRed[1:11]
train_x<-data_x[1:1120,]
test_x<-data_x[1121:1599,]
train_label<-wineRed[1:1120,12]
test_label <- wineRed[1121:1599,12]
prc_test_pred <- knn(train = train_x, test = test_x,cl = train_label, k=30)
library(gmodels)
CrossTable(prc_test_pred, test_label,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted default', 'actual default'))
